{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7bJD_FpLestp"
      },
      "source": [
        "# Depth Estimation\n",
        "\n",
        "> A tool to generate the area of interest maps of images using depth estimation techniques\n",
        "\n",
        "Code was written by Nicholas M. Synovic, Oscar Yanek, and Rohan Sethi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eUPl1Y3afhjX"
      },
      "source": [
        "### Upgrade Python `pip` Tool\n",
        "\n",
        "Upgrade the Python `pip` tool to the latest version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TTjj0EYGfmxm",
        "outputId": "dfeada01-f30e-4604-970a-b3a9d7576a77"
      },
      "outputs": [],
      "source": [
        "%pip install --upgrade pip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbqWSZMQe_B_"
      },
      "source": [
        "### Install Python libaries via `pip`\n",
        "\n",
        "Installed libraries are:\n",
        "\n",
        "- opencv-contrib-python\n",
        "- torch\n",
        "- torchvision\n",
        "- progress\n",
        "- timm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sXq-rWDCJd4w",
        "outputId": "78cea49b-95c8-4ca9-a64f-bbd29844412a"
      },
      "outputs": [],
      "source": [
        "%pip install opencv-contrib-python torch torchvision progress timm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCEpl7l6hKPX"
      },
      "source": [
        "### Import Dependencies "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E4vBBhvvfD_u"
      },
      "outputs": [],
      "source": [
        "from os import listdir\n",
        "from os.path import join\n",
        "from pathlib import PurePath\n",
        "\n",
        "import cv2\n",
        "import numpy\n",
        "import torch\n",
        "from numpy import ndarray\n",
        "from progress.bar import Bar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BUjbgiZ9hVCQ"
      },
      "source": [
        "### Allow Data to be Loaded From Google Drive\n",
        "\n",
        "If you wish to load data from Google Drive, uncomment the following lines."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GkdMd79XhalG",
        "outputId": "ad372c16-91c4-4c23-bbf0-53f786604870"
      },
      "outputs": [],
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQKDGcMOikM_"
      },
      "source": [
        "## Application"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Read Directory\n",
        "\n",
        "Function to read a directory and return a list of filepaths from that directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def readDirectory(dir: str) -> list:\n",
        "    files: list = listdir(dir)\n",
        "    filepaths: list = [join(dir, f) for f in files]\n",
        "    return filepaths"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Estimate Depth with MiDaS\n",
        "\n",
        "Takes a file path to an image (`imagePath`) and an output folder path (default is `./data`; `outputFolder`) as input. A model type (`modelType`) is required as well.\n",
        "\n",
        "**NOTE**: `modelType` must be a compatible MiDaS model type. See [here](https://pytorch.org/hub/intelisl_midas_v2/) for supported model types.\n",
        "\n",
        "It then uses the approach outlined in [1, 2](#citations) to estimate the depth of an image.\n",
        "\n",
        "Area of interest maps are saved in `.jpg` format in the `outputFolder` with the following scheme:\n",
        "\n",
        "- `outputFolder`/FILENAME_MODELTYPE`.jpg`\n",
        "\n",
        "Where FILENAME is the original name of the file without the extension and MODELTYPE is the model type that was used for estimation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def estimateDepth(imagePaths: list, modelType: str, outputFolder: str = \"data\") -> None:\n",
        "    midas = torch.hub.load(\"intel-isl/MiDaS\", modelType)\n",
        "    midas_transforms = torch.hub.load(\"intel-isl/MiDaS\", \"transforms\")\n",
        "\n",
        "    device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "    midas.to(device)\n",
        "    if modelType == \"DPT_Large\" or modelType == \"DPT_Hybrid\":\n",
        "        transform = midas_transforms.dpt_transform\n",
        "    else:\n",
        "        transform = midas_transforms.small_transform\n",
        "\n",
        "    with Bar(f\"Estimating depth with {modelType}...\", max=(len(imagePaths))) as bar:\n",
        "        imagePath: str\n",
        "        for imagePath in imagePaths:\n",
        "            imageName: str = (\n",
        "                PurePath(imagePath).with_suffix(\"\").name\n",
        "                + f'_{modelType.replace(\"_\", \"-\")}.jpg'\n",
        "            )\n",
        "            outputPath: str = join(outputFolder, imageName)\n",
        "\n",
        "            image: ndarray = cv2.imread(imagePath)\n",
        "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "            input_batch = transform(image).to(device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                prediction = midas(input_batch)\n",
        "\n",
        "                prediction = torch.nn.functional.interpolate(\n",
        "                    prediction.unsqueeze(1),\n",
        "                    size=image.shape[:2],\n",
        "                    mode=\"bicubic\",\n",
        "                    align_corners=False,\n",
        "                ).squeeze()\n",
        "\n",
        "            prediction: ndarray = prediction.cpu().numpy()\n",
        "\n",
        "            cv2.imwrite(outputPath, prediction)\n",
        "            bar.next()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Main Method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "oTH2X0mhhbz1",
        "outputId": "70cab19a-d784-4a94-d8c1-87dd16f1f0cc"
      },
      "outputs": [],
      "source": [
        "def main() -> None:\n",
        "    depth_DPTLarge: str = \"DPT_Large\"\n",
        "    depth_DPTHybrid: str = \"DPT_Hybrid\"\n",
        "    depth_MiDaSsmall: str = \"MiDaS_small\"\n",
        "\n",
        "    dir: str = input(\"Image directory to analyze: \")\n",
        "    imagePaths: list = readDirectory(dir)\n",
        "\n",
        "    estimateDepth(imagePaths, depth_DPTHybrid)\n",
        "    estimateDepth(imagePaths, depth_DPTLarge)\n",
        "    estimateDepth(imagePaths, depth_MiDaSsmall)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Citations\n",
        "\n",
        "1. R. Ranftl, A. Bochkovskiy, and V. Koltun, “Vision Transformers for Dense Prediction.” arXiv, Mar. 24, 2021. doi: 10.48550/arXiv.2103.13413.\n",
        "2. R. Ranftl, K. Lasinger, D. Hafner, K. Schindler, and V. Koltun, “Towards Robust Monocular Depth Estimation: Mixing Datasets for Zero-shot Cross-dataset Transfer.” arXiv, Aug. 25, 2020. doi: 10.48550/arXiv.1907.01341.\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "7d6993cb2f9ce9a59d5d7380609d9cb5192a9dedd2735a011418ad9e827eb538"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
